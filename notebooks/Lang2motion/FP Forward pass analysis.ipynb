{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import FoundationXML\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import LangMotionModels\n",
    "import Checkpoints\n",
    "import PythonKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "let np = Python.import(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let device = Device.defaultTFEager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maxTextSequenceLength =  40\n",
    "let maxMotionLength =  150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let datasetSize: DatasetSize = .midi\n",
    "let batchSize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "/// load dataset\n",
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Lang2Motion(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    batchSize: batchSize,\n",
    "    minMotionLength: 20,\n",
    "    maxMotionLength: 150,\n",
    "    trainTestSplit: 1.0,\n",
    "    device: device\n",
    ") { (motionSample: MotionSample) -> LangMotionBatch in    \n",
    "    let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let (motionPart, target) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength)\n",
    "    let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "    let singleBatch = LangMotionBatch(source: source, target: target)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate model\n",
    "let config = LangMotionTransformerConfig(\n",
    "    vocabSize: vocabulary.count,\n",
    "    nbJoints: 47,\n",
    "    nbMixtures: 20,\n",
    "    layerCount: 6,\n",
    "    encoderDepth: 256,\n",
    "    decoderDepth: 512,\n",
    "    feedForwardSize: 2048,\n",
    "    headCount: 16,\n",
    "    dropoutProbability:  0.1,\n",
    "    sentenceMaxPositionalLength: 100,\n",
    "    motionMaxPositionalLength: 500,\n",
    "    encoderSelfAttentionTemp: 1,\n",
    "    decoderSourceAttentionTemp: 1,\n",
    "    decoderSelfAttentionTemp: 1\n",
    ")\n",
    "\n",
    "let runName = \"run_74\"\n",
    "let epoch = 2\n",
    "\n",
    "let runURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let checkpointURL = runURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
    "let motionsURL = runURL.appendingPathComponent(\"generated_motions\", isDirectory: true)\n",
    "try! FileManager().createDirectory(at: motionsURL, withIntermediateDirectories: true)\n",
    "\n",
    "let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(epoch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var log_mixture_pdf2: Tensor<Float> = Tensor<Float>([1.0])\n",
    "var log_bernoulli_pdf2: Tensor<Float> = Tensor<Float>([1.0])\n",
    "var stops2: Tensor<Float> = Tensor<Float>([1.0])\n",
    "// @differentiable(wrt: y_pred)\n",
    "public func _normalMixtureSurrogateLoss2(y_true: LangMotionBatch.Target, y_pred: MixtureModelPreds, args: LossArgs) -> Tensor<Float> {\n",
    "    let TINY: Float = 1e-8\n",
    "    let pi: Float = 3.1415\n",
    "    let nb_mixtures = args.nb_mixtures\n",
    "    let nb_joints = args.nb_joints\n",
    "\n",
    "    let all_means = y_pred.mixtureMeans\n",
    "    let all_variances = y_pred.mixtureVars + TINY\n",
    "    let weights = y_pred.mixtureWeights\n",
    "    let stops = y_pred.stops.squeezingShape(at: 2)\n",
    "    stops2 = stops\n",
    "    \n",
    "    var log_mixture_pdf: Tensor<Float> = Tensor<Float>(zeros: [weights.shape[0], weights.shape[1]], on: args.device) \n",
    "    for mixture_idx in 0..<nb_mixtures {\n",
    "        let start_idx = mixture_idx * nb_joints\n",
    "        let means = all_means[0..., 0..., start_idx..<start_idx + nb_joints]\n",
    "        let variances = all_variances[0..., 0..., start_idx..<start_idx + nb_joints]\n",
    "        let diff = y_true.motion - means\n",
    "        let pdf1 = 1.0 / sqrt(variances * 2.0 * pi)\n",
    "        let pdf2a = diff.squared()\n",
    "        let pdf2 = exp(-(pdf2a) / (2.0 * variances))\n",
    "        let pdf = pdf1 * pdf2\n",
    "        var weighted_pdf = weights[0..., 0..., mixture_idx] * \n",
    "            log(pdf + TINY).sum(alongAxes:2).squeezingShape(at: 2)\n",
    "                \n",
    "        log_mixture_pdf = log_mixture_pdf + weighted_pdf\n",
    "    }\n",
    "\n",
    "    let zeroTensor = Tensor<Float>(repeating: 0.0, shape: log_mixture_pdf.shape, on: args.device)\n",
    "    log_mixture_pdf = log_mixture_pdf.replacing(with: zeroTensor, where: y_true.stops .== Tensor<Float>(1.0, on: args.device))\n",
    "    \n",
    "    let b_pdf1 = Float(1.0) - y_true.stops\n",
    "    let b_pdf2 = Float(1.0) - stops\n",
    "    let bernoulli_pdf = y_true.stops * stops + b_pdf1 * b_pdf2\n",
    "    let log_bernoulli_pdf = log(bernoulli_pdf + TINY)\n",
    "\n",
    "    var mixture_reg: Float = 0.0\n",
    "    if args.mixture_regularizer_type == \"cv\" {\n",
    "        // We want to use (std / mean)^2 = std^2 / mean^2 = var / mean^2.\n",
    "        mixture_reg = weights.variance().scalarized() / \n",
    "            weights.mean().squared().scalarized()\n",
    "    } else if args.mixture_regularizer_type == \"l2\" {\n",
    "        mixture_reg = weights.squared().sum().scalarized()\n",
    "    } else {\n",
    "        mixture_reg = 0.0\n",
    "    }\n",
    "    let loss = -(log_mixture_pdf + log_bernoulli_pdf) +\n",
    "        args.mixture_regularizer * mixture_reg\n",
    "//     print(\"log_mixture_pdf: \\(log_mixture_pdf)\")\n",
    "//     print(\"log_bernoulli_pdf: \\(log_bernoulli_pdf)\")\n",
    "    log_mixture_pdf2 = -log_mixture_pdf\n",
    "    log_bernoulli_pdf2 = -log_bernoulli_pdf\n",
    "    return loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let t1 = Tensor<Float>([1.0])\n",
    "let t2 = Tensor<Int32>([1])\n",
    "var y_pred2: MixtureModelPreds = MixtureModelPreds(mixtureMeans: t1, mixtureVars: t1, mixtureWeights: t1, stops: t1)\n",
    "var y_true2: LangMotionBatch.Target = LangMotionBatch.Target(sampleID: t2, motion: t1, stops:t1, segmentIDs: t2, origMotionFramesCount: t2)\n",
    "// @differentiable(wrt: y_pred)\n",
    "public func normalMixtureSurrogateLoss2(y_pred: MixtureModelPreds, y_true: LangMotionBatch.Target, args: LossArgs) -> (Tensor<Float>, Tensor<Float>) {\n",
    "    // masking\n",
    "    var y_pred = y_pred.squeezed()\n",
    "    var y_true = y_true.squeezed()\n",
    "    let ids = Tensor<Int32>(rangeFrom: 0, to: Int32(y_true.stops.shape[1]), stride: 1, on: args.device)\n",
    "    let indices = ids.gathering(where: y_true.segmentIDs .!= Tensor(0, on: args.device))\n",
    "    y_pred = y_pred.gathering(atIndices: indices, alongAxis: 1)\n",
    "    y_true = y_true.gathering(atIndices: indices, alongAxis: 1)\n",
    "    \n",
    "    y_pred2 = y_pred\n",
    "    y_true2 = y_true\n",
    "    \n",
    "    let loss = _normalMixtureSurrogateLoss2(y_true: y_true, y_pred: y_pred, args: args)    \n",
    "    let mean_loss = loss.mean()\n",
    "    return (mean_loss, loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Loss function\n",
    "let args = LossArgs(\n",
    "        nb_joints: config.nbJoints,\n",
    "        nb_mixtures: config.nbMixtures,\n",
    "        mixture_regularizer_type: \"None\",  // [\"cv\", \"l2\", \"None\"]\n",
    "        mixture_regularizer: 0.0,\n",
    "        device: device\n",
    ")\n",
    "\n",
    "// @differentiable(wrt: y_pred)\n",
    "func embeddedNormalMixtureSurrogateLoss(y_pred: LangMotionTransformerOutput<Float>, y_true: LangMotionBatch.Target) -> (Tensor<Float>, Tensor<Float>) {\n",
    "    return normalMixtureSurrogateLoss2(y_pred: y_pred.preds, y_true: y_true, args: args)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let shortSamples = dataset.motionSamples.filter { $0.motion.shape[0] < 100 }\n",
    "print(shortSamples.count)\n",
    "shortSamples.map { $0.motion.shape[0]} [0...10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let motionSample = dataset.motionSamples[0]\n",
    "let motionSample = shortSamples[1]\n",
    "print(\"sampleID: \\(motionSample.sampleID)\")\n",
    "print(motionSample.description)\n",
    "print(motionSample.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "let (motionPart, target) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength)\n",
    "let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "let singleBatch = LangMotionBatch(source: source, target: target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## source motion part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.source.motionPart.printMotionPart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(singleBatch.source.motionPart.motion[0..., 0..., 0]*1e1)/1e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.source.motionPart.segmentIDs[0, 0..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.target.printTarget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(singleBatch.target.motion[0..., 0..., 0]*1e1)/1e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.target.segmentIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor<Int32>(singleBatch.target.stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model(batch), transformerOutput, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let transformerOutput = model(singleBatch.source)\n",
    "let singlePreds = transformerOutput.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePreds.printPreds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func tensorShow(_ tensor: Tensor<Float>, cmapRange: Int = 6) {\n",
    "    plt.figure(figsize: [5, 5])\n",
    "    plt.imshow(tensor.makeNumpyArray(), aspect: \"auto\", cmap: \"Spectral\", vmin: -cmapRange, vmax: cmapRange)\n",
    "    plt.show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (mean_loss, loss) = embeddedNormalMixtureSurrogateLoss(y_pred: transformerOutput, y_true: singleBatch.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean_loss: \\(mean_loss)\")\n",
    "print(\"loss.shape: \\(loss.shape)\")\n",
    "round(loss*1e2)/1e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what about stop signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true2.printTarget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(y_true2.motion[0..., 0..., 0]*1e1)/1e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true2.stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log_mixture_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_mixture_pdf2.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log_bernoulli_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_bernoulli_pdf2.scalars)\n",
    "plt.plot(log_bernoulli_pdf2.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stops2)\n",
    "plt.plot(stops2.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
