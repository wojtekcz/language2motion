{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import FoundationXML\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import LangMotionModels\n",
    "import Checkpoints\n",
    "import PythonKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "let np = Python.import(\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let device = Device.defaultTFEager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maxTextSequenceLength =  40\n",
    "let maxMotionLength =  100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let datasetSize: DatasetSize = .full\n",
    "let batchSize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)\n",
    "\n",
    "/// instantiate model\n",
    "let modelSize = 128\n",
    "let config = LangMotionTransformerConfig(\n",
    "    vocabSize: vocabulary.count,\n",
    "    nbJoints: 47, // TODO: get value from dataset\n",
    "    nbMixtures: 20,\n",
    "    layerCount: 6,\n",
    "    modelSize: modelSize,\n",
    "    feedForwardSize: 512,\n",
    "    headCount: 4,\n",
    "    dropoutProbability:  0.1,\n",
    "    sentenceMaxPositionalLength: 100,\n",
    "    motionMaxPositionalLength: 500,\n",
    "    motionPositionalEncodingSize: 32,\n",
    "    encoderSelfAttentionTemp: 1,\n",
    "    decoderSourceAttentionTemp: 1,\n",
    "    decoderSelfAttentionTemp: 1\n",
    "//     encoderSelfAttentionTemp: sqrt(Double(modelSize)),\n",
    "//     decoderSourceAttentionTemp: sqrt(Double(modelSize)),\n",
    "//     decoderSelfAttentionTemp: Double(modelSize)\n",
    ")\n",
    "\n",
    "let runName = \"run_60\"\n",
    "let epoch = 160\n",
    "\n",
    "let runURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let checkpointURL = runURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
    "let motionsURL = runURL.appendingPathComponent(\"generated_motions\", isDirectory: true)\n",
    "try! FileManager().createDirectory(at: motionsURL, withIntermediateDirectories: true)\n",
    "\n",
    "let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(epoch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "/// load dataset\n",
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Lang2Motion(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    batchSize: batchSize,\n",
    "    trainTestSplit: 1.0,\n",
    "    device: device\n",
    ") { (motionSample: MotionSample) -> LangMotionBatch in    \n",
    "    let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let (motionPart, target) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength, shiftMaskRight: true)\n",
    "    let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "    let singleBatch = LangMotionBatch(source: source, target: target)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Loss function\n",
    "let args = LossArgs(\n",
    "        nb_joints: config.nbJoints,\n",
    "        nb_mixtures: config.nbMixtures,\n",
    "        mixture_regularizer_type: \"None\",  // [\"cv\", \"l2\", \"None\"]\n",
    "        mixture_regularizer: 0.0,\n",
    "        device: device\n",
    ")\n",
    "\n",
    "@differentiable(wrt: y_pred)\n",
    "public func normalMixtureSurrogateLoss2(y_pred: MixtureModelPreds, y_true: LangMotionBatch.Target, args: LossArgs) -> (Tensor<Float>, Tensor<Float>) {\n",
    "    // masking\n",
    "    var y_pred = y_pred.squeezed()\n",
    "    var y_true = y_true.squeezed()\n",
    "    let ids = Tensor<Int32>(rangeFrom: 0, to: Int32(y_true.stops.shape[1]), stride: 1, on: args.device)\n",
    "    let indices = ids.gathering(where: y_true.stops .!= Tensor(1, on: args.device))\n",
    "    y_pred = y_pred.gathering(atIndices: indices, alongAxis: 1)\n",
    "    y_true = y_true.gathering(atIndices: indices, alongAxis: 1)\n",
    "    \n",
    "    let loss = _normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
    "    let mean_loss = loss.mean()\n",
    "    return (mean_loss, loss)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: visualize data:\n",
    "// - mask(s)\n",
    "// - signals that go through the decoder\n",
    "// + check if loss changes when text changes but motion doesn't - changes\n",
    "// + do we still have one step with big loss? yes, but only first one\n",
    "// TODO: what would be loss of generated sequence?\n",
    "// + is learning to stop working? no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let motionSample = dataset.motionSamples[0]\n",
    "print(\"sampleID: \\(motionSample.sampleID)\")\n",
    "print(motionSample.description)\n",
    "print(motionSample.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let s = \"A person plays the guitar, dances and kicks, then kneels down.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let sentence = textProcessor.preprocess(sentence: s, maxTextSequenceLength: maxTextSequenceLength)\n",
    "let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "let (motionPart, target) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength, shiftMaskRight: true)\n",
    "let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "let singleBatch = LangMotionBatch(source: source, target: target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformerOutput, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let transformerOutput = model(singleBatch.source)\n",
    "let singlePreds = transformerOutput.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlePreds.printPreds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func tensorShow(_ tensor: Tensor<Float>, cmapRange: Int = 6) {\n",
    "    plt.figure(figsize: [5, 5])\n",
    "    plt.imshow(tensor.makeNumpyArray(), aspect: \"auto\", cmap: \"Spectral\", vmin: -cmapRange, vmax: cmapRange)\n",
    "    plt.show()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (avg_loss, loss) = normalMixtureSurrogateLoss2(y_pred: singlePreds, y_true: singleBatch.target, args: args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.target.motion[0..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batched computation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let batch = LangMotionBatch.reduceDataBatches([singleBatch, singleBatch])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch.target.printTarget()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch.source.printSource()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let batchPreds = model(batch.source)\n",
    "batchPreds.printPreds()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let loss = embeddedNormalMixtureSurrogateLoss(y_pred: singlePreds, y_true: singleBatch.target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second sample, with old 1-dim attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let motionSample2 = dataset.motionSamples[0]\n",
    "print(\"sampleID: \\(motionSample2.sampleID)\")\n",
    "print(motionSample2.description)\n",
    "print(motionSample2.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let sentence2 = textProcessor.preprocess(sentence: motionSample2.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "let (motionPart2, target2) = LangMotionBatch.preprocessTargetMotion2(sampleID: motionSample2.sampleID, motion: motionSample2.motion, maxMotionLength: maxMotionLength)\n",
    "let source2 = LangMotionBatch.Source(sentence: sentence2, motionPart: motionPart2, sourceAttentionMask: sentence2.mask)\n",
    "let singleBatch2 = LangMotionBatch(source: source2, target: target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.source.sourceAttentionMask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch2.source.sourceAttentionMask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let transformerOutput2 = model(singleBatch2.source)\n",
    "let singlePreds2 = transformerOutput2.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (avg_loss2, loss2) = normalMixtureSurrogateLoss2(y_pred: singlePreds2, y_true: singleBatch2.target, args: args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_loss2)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transformerOutput2.decoded.lastLayerOutput.mean(),\n",
    "transformerOutput2.decoded.lastLayerOutput.max(),\n",
    "transformerOutput2.decoded.lastLayerOutput.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transformerOutput.decoded.lastLayerOutput.mean(),\n",
    "transformerOutput.decoded.lastLayerOutput.max(),\n",
    "transformerOutput.decoded.lastLayerOutput.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformerOutput2.decoded.lastLayerOutput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformerOutput2.decoded.lastLayerOutput - transformerOutput.decoded.lastLayerOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorShow((transformerOutput2.decoded.lastLayerOutput).squeezingShape(at: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorShow((transformerOutput.decoded.lastLayerOutput).squeezingShape(at: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorShow((transformerOutput2.decoded.lastLayerOutput - transformerOutput.decoded.lastLayerOutput).squeezingShape(at: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move self-attention mask to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// https://www.tensorflow.org/tutorials/text/transformer#masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var motionPartFlag = Tensor<Int32>(repeating: 1, shape: [1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionPartFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionPartFlag[0, 9] = Tensor<Int32>(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionPartFlag[0, 8] = Tensor<Int32>(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "motionPartFlag[0, 0] = Tensor<Int32>(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionPartFlag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let motionPartMask = LangMotionBatch.makeStandardMask(target: motionPartFlag, pad: 0)\n",
    "motionPartMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(motionPartMask.squeezingShape(at: 0).makeNumpyArray())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func makeStandardMask(target: Tensor<Int32>, pad: Int32) -> Tensor<Float> {\n",
    "    var targetMask = Tensor(zerosLike: target)\n",
    "        .replacing(with: Tensor(onesLike: target), where: target .!= Tensor.init(pad))\n",
    "        .expandingShape(at: -2)\n",
    "    targetMask *= subsequentMask(size: target.shape.last!)\n",
    "    return Tensor<Float>(targetMask)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func subsequentMask(size: Int) -> Tensor<Int32> {\n",
    "    let attentionShape = [1, size, size]\n",
    "    return Tensor<Int32>(ones: TensorShape(attentionShape))\n",
    "        .bandPart(subdiagonalCount: 0, superdiagonalCount: -1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let subsequentMaskT = subsequentMask(size: 8)\n",
    "subsequentMaskT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequentMaskT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let size = 8\n",
    "let attentionShape = [size, size]\n",
    "let t = 1 - Tensor<Int32>(ones: TensorShape(attentionShape))\n",
    "    .bandPart(subdiagonalCount: -1, superdiagonalCount: 0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func subsequentMaskV2(size: Int) -> Tensor<Int32> {\n",
    "    let attentionShape = [1, size, size]\n",
    "    return 1 - Tensor<Int32>(ones: TensorShape(attentionShape))\n",
    "        .bandPart(subdiagonalCount: -1, superdiagonalCount: 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let subsequentMaskT2 = subsequentMaskV2(size: 8)\n",
    "subsequentMaskT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func makeStandardMaskV2(target: Tensor<Int32>, pad: Int32) -> Tensor<Float> {\n",
    "    var targetMask = Tensor(zerosLike: target)\n",
    "        .replacing(with: Tensor(onesLike: target), where: target .!= Tensor.init(pad))\n",
    "        .expandingShape(at: -2)\n",
    "    targetMask *= subsequentMaskV2(size: target.shape.last!)\n",
    "    return Tensor<Float>(targetMask)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let motionPartMask2 = makeStandardMaskV2(target: motionPartFlag, pad: 0)\n",
    "motionPartMask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(motionPartMask2.squeezingShape(at: 0).makeNumpyArray())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test both self-attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sampleID: \\(motionSample.sampleID)\")\n",
    "print(motionSample.description)\n",
    "print(motionSample.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let motionSample2 = dataset.motionSamples[0]\n",
    "print(\"sampleID: \\(motionSample2.sampleID)\")\n",
    "print(motionSample2.description)\n",
    "print(motionSample2.annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let sentence2 = textProcessor.preprocess(sentence: motionSample2.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "let (motionPart2, target2) = LangMotionBatch.preprocessTargetMotion2(sampleID: motionSample2.sampleID, motion: motionSample2.motion, maxMotionLength: maxMotionLength, shiftRight: true)\n",
    "let source2 = LangMotionBatch.Source(sentence: sentence2, motionPart: motionPart2, sourceAttentionMask: sentence2.mask)\n",
    "let singleBatch2 = LangMotionBatch(source: source2, target: target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let transformerOutput2 = model(singleBatch2.source)\n",
    "let singlePreds2 = transformerOutput2.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (avg_loss2, loss2) = normalMixtureSurrogateLoss2(y_pred: singlePreds2, y_true: singleBatch2.target, args: args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch.source.motionPart.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleBatch2.source.motionPart.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_loss2)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss2.scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((loss2 - loss).scalars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
