{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion generation from checkpoints"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// To run in VSCode: Open notebook in jupyter lab and run installation cell in there first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import FoundationXML\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import LangMotionModels\n",
    "import Checkpoints\n",
    "import PythonKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let np  = Python.import(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let device = Device.defaultTFEager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maxTextSequenceLength =  20\n",
    "let maxMotionLength =  50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let datasetSize: DatasetSize = .full\n",
    "let batchSize = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)\n",
    "\n",
    "// model config\n",
    "let config = LangMotionTransformerConfig(\n",
    "    vocabSize: vocabulary.count,\n",
    "    nbJoints: 47, // TODO: get value from dataset\n",
    "    nbMixtures: 20,\n",
    "    layerCount: 6,\n",
    "    modelSize: 128,\n",
    "    feedForwardSize: 512,\n",
    "    headCount: 4,\n",
    "    dropoutProbability: 0.1,\n",
    "    sentenceMaxPositionalLength: 100, \n",
    "    motionMaxPositionalLength: 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Lang2Motion(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    batchSize: batchSize,\n",
    "    minMotionLength: 20,\n",
    "    maxMotionLength: 50,\n",
    "    trainTestSplit: 1.0,\n",
    "    device: device\n",
    ") { (motionSample: MotionSample) -> LangMotionBatch in    \n",
    "    let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let (motionPart, target) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength)\n",
    "    let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "    let singleBatch = LangMotionBatch(data: source,label: target)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public class MotionDecoder2 {\n",
    "    public static func performNormalMixtureSampling(preds: MixtureModelPreds, nb_joints: Int, nb_mixtures: Int, maxMotionLength: Int) -> (motion: Tensor<Float>, log_probs: [Float], done: Tensor<Int32>) {\n",
    "        let TINY: Float = 1e-8\n",
    "        let motionLength = preds.mixtureMeans.shape[1]\n",
    "\n",
    "        var motion: Tensor<Float> = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        var log_probs: [Float] = [Float](repeating:0.0, count: motionLength)\n",
    "        var done: [Int32] = [Int32](repeating: 0, count: motionLength)\n",
    "\n",
    "        let all_means = preds.mixtureMeans.squeezingShape(at: 0)\n",
    "        let all_variances = preds.mixtureVars.squeezingShape(at: 0) + TINY\n",
    "        let weights = preds.mixtureWeights.squeezingShape(at: 0)\n",
    "        let stops = preds.stops[0, 0..., 0]\n",
    "\n",
    "        /// Sample joint values.\n",
    "        var samples = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        var means = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        var variances = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        for width_idx in 0..<motionLength {\n",
    "            // Decide which mixture to sample from\n",
    "            let p = weights[width_idx].scalars.map { Double($0)}\n",
    "            assert(p.count == nb_mixtures)\n",
    "            if weights[width_idx].isNaN.any() {\n",
    "                print(\"performNormalMixtureSampling: still NaNs?!\")\n",
    "                print(p)\n",
    "            }\n",
    "            let mixture_idx = randomNumber(probabilities: p) //np.random.choice(range(nb_mixtures), p=p)\n",
    "\n",
    "            /// Sample from it.\n",
    "            let start_idx = mixture_idx * nb_joints\n",
    "            let m = all_means[width_idx, start_idx..<start_idx + nb_joints]\n",
    "            let v = all_variances[width_idx, start_idx..<start_idx + nb_joints]\n",
    "            assert(m.shape == [nb_joints])\n",
    "            assert(m.shape == v.shape)\n",
    "            // https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
    "            let s = np.random.normal(m.scalars, v.scalars)\n",
    "            samples[width_idx, 0...] = Tensor<Float>(Array(s)!)\n",
    "            means[width_idx, 0...] = m\n",
    "            variances[width_idx, 0...] = v\n",
    "        }\n",
    "\n",
    "        for idx in 0..<motionLength {\n",
    "            let sample = samples[idx]\n",
    "            let stop: Float = stops[idx].scalar!\n",
    "            // if done[idx] != 0 {\n",
    "            //     continue\n",
    "            // }\n",
    "            motion[idx] = sample\n",
    "            // https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.binomial.html\n",
    "            let sampled_stop: Int = Int(np.random.binomial(n: 1, p: stop))!\n",
    "            log_probs[idx] += log(gaussian_pdf(sample: sample, means: means[idx], variances: variances[idx])).sum().scalar!\n",
    "            log_probs[idx] += log(bernoulli_pdf(sample: sampled_stop, p: stop))\n",
    "            done[idx] = (sampled_stop == 0) ? 1 : 0\n",
    "        }\n",
    "        return (motion: motion, log_probs: log_probs, done: Tensor(done))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MotionGaussianMixtureModel {\n",
    "    @differentiable\n",
    "    func forwardStep2(_ x: Tensor<Float>) -> MixtureModelPreds {\n",
    "        // bs x input_size\n",
    "        // Processing gaussian mixture params:\n",
    "        let mixtureMeans = linearMixtureMeans(x)\n",
    "        let mixtureVars = softplus(linearMixtureVars(x))\n",
    "        var mixtureWeights = softmax(linearMixtureWeights(x), alongAxis: 1)\n",
    "        \n",
    "        if mixtureWeights.isNaN.any() {\n",
    "            // print(\"Fixing NaNs\")\n",
    "            var divider = 1.0\n",
    "            let double_x = Tensor<Double>(linearMixtureWeights(x))\n",
    "            while mixtureWeights.isNaN.any() {\n",
    "                mixtureWeights = Tensor<Float>(softmax(double_x/divider, alongAxis: 1))\n",
    "                divider *= 10.0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // stop\n",
    "        let stop = sigmoid(linearStop(x))\n",
    "        // merge\n",
    "        let mixtureStepPreds = MixtureModelPreds(mixtureMeans: mixtureMeans, mixtureVars: mixtureVars, mixtureWeights: mixtureWeights, stops: stop)\n",
    "        return mixtureStepPreds\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction2(_ input: Tensor<Float>) -> MixtureModelPreds {\n",
    "        let targetLength = input.shape[1]\n",
    "        // TODO: use time distributed layers\n",
    "        // Run through mixture_model one time step at a time\n",
    "        var all_outputs: [MixtureModelPreds] = []\n",
    "        for t in 0..<targetLength {\n",
    "            let decoder_input: Tensor<Float> = input[0..., t]\n",
    "            let decoder_output = self.forwardStep2(decoder_input)\n",
    "            all_outputs.append(decoder_output)\n",
    "        }\n",
    "        \n",
    "        let all_outputs_struct = MixtureModelPreds(stacking: all_outputs, alongAxis: 1)\n",
    "        return all_outputs_struct\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// public class MotionDecoder2 {\n",
    "\n",
    "extension MotionDecoder2 {\n",
    "    public static func greedyDecodeMotion2(\n",
    "        sentence: LangMotionBatch.Sentence, \n",
    "        startMotion: Tensor<Float>?,\n",
    "        transformer: LangMotionTransformer, \n",
    "        nbJoints: Int, \n",
    "        nbMixtures: Int, \n",
    "        maxMotionLength: Int,\n",
    "        memoryMultiplier: Float = 1.0\n",
    "    ) -> Tensor<Float> {\n",
    "        print(\"\\nEncode:\")\n",
    "        print(\"======\")\n",
    "        let memory = transformer.encode(input: sentence) * memoryMultiplier\n",
    "        print(\"  memory.count: \\(memory.shape)\")     \n",
    "\n",
    "        print(\"\\nGenerate:\")\n",
    "        print(\"=========\")\n",
    "\n",
    "        // start with tensor for neutral motion frame\n",
    "        let zeroMotionFrame = LangMotionBatch.zeroMotionFrame(nbJoints: nbJoints).expandingShape(at: 0)\n",
    "        var ys: Tensor<Float> = zeroMotionFrame\n",
    "        // or with supplied motion\n",
    "        if startMotion != nil {\n",
    "            ys = Tensor<Float>(concatenating: [zeroMotionFrame, startMotion!.expandingShape(at:0)], alongAxis: 1)\n",
    "        }\n",
    "\n",
    "        print(\"ys.shape: \\(ys.shape)\")\n",
    "        \n",
    "        let maxMotionLength2 = maxMotionLength-ys.shape[1]+1\n",
    "        \n",
    "        for step in 0..<maxMotionLength2 {\n",
    "            // print(\"step: \\(step)\")\n",
    "            print(\".\", terminator:\"\")\n",
    "            // prepare input\n",
    "            let motionPartFlag = Tensor<Int32>(repeating: 1, shape: [1, ys.shape[1]])\n",
    "            let motionPartMask = LangMotionBatch.makeStandardMask(target: motionPartFlag, pad: 0)\n",
    "            let previous_ys = Tensor<Float>(concatenating: [zeroMotionFrame, ys], alongAxis: 1)[0..., 0...ys.shape[1]-1, 0...]\n",
    "            var motionStartFlag = Tensor<Float>(zeros: [ys.shape[1], 1]).expandingShape(at: 0) // FIXME: refactor getting motionStartFlag\n",
    "            motionStartFlag[0, 0, 0] = Tensor(1.0)\n",
    "            let motionPart = LangMotionBatch.MotionPart(motion: ys, mask: motionPartMask, previousMotion: previous_ys, startFlag: motionStartFlag, motionFlag: motionPartFlag.expandingShape(at: 2))\n",
    "            let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "            // print(\"\\(step), sourceAttentionMask.shape: \\(source.sourceAttentionMask.shape)\")\n",
    "            // decode motion\n",
    "            let dedoderOutput = transformer.decode(sourceMask: source.sourceAttentionMask, motionPart: motionPart, memory: memory)\n",
    "            \n",
    "            let mixtureModelInput = Tensor<Float>(concatenating: dedoderOutput.allOutputs, alongAxis: 2)\n",
    "            let mixtureModelInput2 = mixtureModelInput[0...,-1].expandingShape(at: 0)\n",
    "            let singlePreds = transformer.mixtureModel.callAsFunction2(mixtureModelInput2)\n",
    "\n",
    "//             if singlePreds.mixtureWeights.isNaN.any() {\n",
    "//                 print(singlePreds.mixtureWeights)\n",
    "//                 print(mixtureModelInput2)\n",
    "//             }\n",
    "            \n",
    "            // perform sampling\n",
    "            let (sampledMotion, _, _) = Self.performNormalMixtureSampling(\n",
    "                preds: singlePreds, nb_joints: nbJoints, nb_mixtures: nbMixtures, maxMotionLength: maxMotionLength)\n",
    "            \n",
    "            // concatenate motion\n",
    "            ys = Tensor(concatenating: [ys, sampledMotion.expandingShape(at: 0)], alongAxis: 1)\n",
    "        }\n",
    "        print()\n",
    "        return ys.squeezingShape(at:0)[1...]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct SampleMotionClip {\n",
    "    var sampleID: Int\n",
    "    var start: Int = 0\n",
    "    var length: Int = 1\n",
    "}\n",
    "\n",
    "public func getClippedMotionFrames(dataset: Lang2Motion, clipInfo: SampleMotionClip?) -> Tensor<Float>? {\n",
    "    if clipInfo != nil {\n",
    "    \n",
    "    let ms: MotionSample = dataset.motionSamples.filter { $0.sampleID == clipInfo!.sampleID } [0]\n",
    "    let clippedMotionFrames = ms.motion[clipInfo!.start..<clipInfo!.start+clipInfo!.length]\n",
    "    return clippedMotionFrames\n",
    "    } else {\n",
    "        return nil\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func greedyDecodeMotion2(dataset: Lang2Motion, model: LangMotionTransformer, sentence: String, leadingFrames: SampleMotionClip?, prefix: String = \"prefix\", saveMotion: Bool = true, memoryMultiplier: Float = 0.0, motionsURL: URL?) {\n",
    "    let startMotion: Tensor<Float>? = getClippedMotionFrames(dataset: dataset, clipInfo: leadingFrames)\n",
    "    var leadingFramesStr = \"0\"\n",
    "    if startMotion != nil {\n",
    "        leadingFramesStr = \"\\(startMotion!.shape[0])\"\n",
    "    }\n",
    "    // TODO: incorporate done/stop signal\n",
    "    Context.local.learningPhase = .inference\n",
    "    print(\"\\ngreedyDecodeMotion(sentence: \\\"\\(sentence)\\\")\")\n",
    "\n",
    "    let processedSentence = textProcessor.preprocess(sentence: sentence, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    processedSentence.printSentence()\n",
    "\n",
    "    let decodedMotion = MotionDecoder2.greedyDecodeMotion2(\n",
    "        sentence: processedSentence, \n",
    "        startMotion: startMotion,\n",
    "        transformer: model, \n",
    "        nbJoints: config.nbJoints, \n",
    "        nbMixtures: config.nbMixtures, \n",
    "        maxMotionLength: maxMotionLength,\n",
    "        memoryMultiplier: memoryMultiplier\n",
    "    )\n",
    "    print(\"  decodedMotion: min: \\(decodedMotion.min()), max: \\(decodedMotion.max())\")\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(decodedMotion)\n",
    "    print(\"  descaledMotion.shape: \\(descaledMotion.shape)\")\n",
    "    print(\"  descaledMotion: min: \\(descaledMotion.min()), max: \\(descaledMotion.max())\")\n",
    "    var imageURL: URL? = nil\n",
    "    \n",
    "    if !saveMotion { imageURL = nil } else {\n",
    "        imageURL = motionsURL!.appendingPathComponent(\"\\(prefix).png\")\n",
    "    }\n",
    "    // use joint groupping\n",
    "    let grouppedJointsMotion = MotionSample.grouppedJoints(motion: descaledMotion, jointNames: dataset.motionSamples[0].jointNames)\n",
    "    motionToImg(url: imageURL, motion: grouppedJointsMotion, motionFlag: nil, padTo: maxMotionLength, descr: \"\\(sentence), LF: \\(leadingFramesStr)\", cmapRange: 1.0)\n",
    "\n",
    "    if saveMotion {\n",
    "        print(\"Saved image: \\(imageURL!.path)\")\n",
    "        let jointNames = dataset.motionSamples[0].jointNames\n",
    "        let mmmXMLDoc = MMMWriter.getMMMXMLDoc(jointNames: jointNames, motion: descaledMotion)\n",
    "        let mmmURL = motionsURL!.appendingPathComponent(\"\\(prefix).mmm.xml\")\n",
    "        try! mmmXMLDoc.xmlData(options: XMLNode.Options.nodePrettyPrint).write(to: mmmURL)\n",
    "        print(\"Saved motion: \\(mmmURL.path)\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func showMotionSample(_ motionSample: MotionSample) {\n",
    "    let motion = motionSample.motion\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(motion)\n",
    "    let sentence = \"sample_id=\\(motionSample.sampleID), ann=\\(motionSample.annotations[0])\"\n",
    "\n",
    "    print(\"motion: min: \\(motion.min()), max: \\(motion.max())\")\n",
    "    print(\"descaledMotion.shape: \\(descaledMotion.shape)\")\n",
    "    print(\"descaledMotion: min: \\(descaledMotion.min()), max: \\(descaledMotion.max())\")\n",
    "\n",
    "    // use joint groupping\n",
    "    let jointNames = dataset.motionSamples[0].jointNames\n",
    "    let grouppedJointsMotion = MotionSample.grouppedJoints(motion: descaledMotion, jointNames: dataset.motionSamples[0].jointNames)\n",
    "    motionToImg(url: nil, motion: grouppedJointsMotion, motionFlag: nil, padTo: maxMotionLength, descr: sentence, cmapRange: 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func showMotion(motion: Tensor<Float>) {\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(motion)\n",
    "    let grouppedJointsMotion = MotionSample.grouppedJoints(motion: descaledMotion, jointNames: dataset.motionSamples[0].jointNames)\n",
    "    motionToImg(url: nil, motion: grouppedJointsMotion, motionFlag: nil, padTo: maxMotionLength, descr: \"\", cmapRange: 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func saveMotionToMMM(motion: Tensor<Float>, mmmURL: URL) {\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(motion)\n",
    "    let jointNames = dataset.motionSamples[0].jointNames\n",
    "    let mmmXMLDoc = MMMWriter.getMMMXMLDoc(jointNames: jointNames, motion: descaledMotion)\n",
    "    try! mmmXMLDoc.xmlData(options: XMLNode.Options.nodePrettyPrint).write(to: mmmURL)\n",
    "    print(\"Saved motion: \\(mmmURL.path)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let runName = \"run_42\"\n",
    "let epoch = 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let runURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let checkpointURL = runURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
    "let motionsURL = runURL.appendingPathComponent(\"generated_motions\", isDirectory: true)\n",
    "try! FileManager().createDirectory(at: motionsURL, withIntermediateDirectories: true)\n",
    "\n",
    "// let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(epoch)\")\n",
    "// let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode using leading motion frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find suitable motion sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let annotations = dataset.langRecs\n",
    "annotations.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dics = annotations[0..<3].map { [\"sampleID\": \"\\($0.sampleID)\", \"text\": $0.text] }\n",
    "dics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save annotations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let encoder = JSONEncoder()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let jsonData = try? encoder.encode(dic[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let dic = [\"2\": \"B\", \"1\": \"A\", \"3\": \"C\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(type(of:dic))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let encoder = JSONEncoder()\n",
    "if let jsonData = try? encoder.encode(dic) {\n",
    "    if let jsonString = String(data: jsonData, encoding: .utf8) {\n",
    "        print(jsonString)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let dic2 = dics[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(type(of:dic2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let encoder = JSONEncoder()\n",
    "if let jsonData = try? encoder.encode(dics) {\n",
    "    if let jsonString = String(data: jsonData, encoding: .utf8) {\n",
    "        print(jsonString)\n",
    "        let URL()\n",
    "        jsonString.write(to: , atomically: , encoding: )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let search = \"run\"\n",
    "let filteredAnns = annotations.filter { $0.text.contains(search) }\n",
    "print(filteredAnns.count)\n",
    "let startIdx = 0\n",
    "filteredAnns[startIdx..<startIdx+min(10, filteredAnns.count)].map { (sampleID: $0.sampleID, ann: $0.text) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select motion sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let selAnn = filteredAnns[8]\n",
    "let selSampleInfo = (sampleID: selAnn.sampleID, text: selAnn.text, length: selAnn.motionSample.motion.shape[0])\n",
    "\n",
    "print(\"Selected motion sample\")\n",
    "print(selSampleInfo)\n",
    "showMotionSample(selAnn.motionSample)\n",
    "saveMotionToMMM(motion: selAnn.motionSample.motion, mmmURL: motionsURL.appendingPathComponent(\"sample.mmm.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let clipInfo = SampleMotionClip(sampleID: selSampleInfo.sampleID, start: 5, length: 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let clippedMotionFrames: Tensor<Float>? = getClippedMotionFrames(dataset: dataset, clipInfo: clipInfo)\n",
    "print(\"\\n**** \\(clipInfo) ****\\n\")\n",
    "print(\"Actual length: \\(clippedMotionFrames!.shape[0])\")\n",
    "print(\"clippedMotionFrames: min: \\(clippedMotionFrames!.min()), max: \\(clippedMotionFrames!.max())\")\n",
    "showMotion(motion: clippedMotionFrames!)\n",
    "saveMotionToMMM(motion: clippedMotionFrames!, mmmURL: motionsURL.appendingPathComponent(\"clip.mmm.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let runName = \"run_42\"\n",
    "let epoch = 79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let runURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let checkpointURL = runURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
    "let motionsURL = runURL.appendingPathComponent(\"generated_motions\", isDirectory: true)\n",
    "try! FileManager().createDirectory(at: motionsURL, withIntermediateDirectories: true)\n",
    "\n",
    "let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(epoch)\")\n",
    "// let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var genNum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var s: String = \"\"\n",
    "var lf: SampleMotionClip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// s = \"A person is walking forwards five steps.\"\n",
    "// s = \"A person is walking forwards.\"\n",
    "// lf = SampleMotionClip(sampleID: 1, start: 26, length: 2)\n",
    "lf = nil\n",
    "\n",
    "// s = \"A person plays the guitar.\"\n",
    "// lf = SampleMotionClip(sampleID: 1438, start: 14, length: 10)\n",
    "\n",
    "// s = \"The human plays air guitar and sways ans stands still.\"\n",
    "// s = \"The human walks in the straight line.\"\n",
    "// s = \"Someone is jogging.\"\n",
    "\n",
    "// s = \"a person waves with his both arms\"\n",
    "// s = \"a person is waving his hand.\"\n",
    "\n",
    "s = \"A person runs.\"\n",
    "// s = \"The human is running\"\n",
    "// lf = SampleMotionClip(sampleID: 449, start: 14, length: 10)\n",
    "\n",
    "// s = \"A person kneels down.\"\n",
    "// s = \"A human walking backwards\"\n",
    "// s = \"A person walks 4 steps forward.\"\n",
    "\n",
    "// s = \"A person performs a high kick\"\n",
    "// lf = SampleMotionClip(sampleID: 610, start: 5, length: 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greedyDecodeMotion2(dataset: dataset, model: model, sentence: s, leadingFrames: lf, \n",
    "    prefix: \"epoch_\\(epoch)_motion_\\(genNum)\", \n",
    "    saveMotion: true,  memoryMultiplier: 1.0, motionsURL: motionsURL\n",
    ")\n",
    "genNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
