{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion generation from checkpoints"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// To run in VSCode: Open notebook in jupyter lab and run installation cell in there first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import FoundationXML\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import LangMotionModels\n",
    "import Checkpoints\n",
    "import PythonKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let np  = Python.import(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let device = Device.defaultTFEager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maxTextSequenceLength =  20\n",
    "let maxMotionLength =  100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let datasetSize: DatasetSize = .multi_full\n",
    "let batchSize = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)\n",
    "\n",
    "// model config\n",
    "let config = LangMotionTransformerConfig(\n",
    "    vocabSize: vocabulary.count,\n",
    "    nbJoints: 47, // TODO: get value from dataset\n",
    "    nbMixtures: 20,\n",
    "    layerCount: 6,\n",
    "    modelSize: 256,\n",
    "    feedForwardSize: 1024,\n",
    "    headCount: 8,\n",
    "    dropoutProbability: 0.1,\n",
    "    sentenceMaxPositionalLength: 100, \n",
    "    motionMaxPositionalLength: 500,\n",
    "    doMotionDense: false\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Lang2Motion(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    batchSize: batchSize,\n",
    "    minMotionLength: 10,\n",
    "    maxMotionLength: 100,\n",
    "    trainTestSplit: 1.0,\n",
    "    device: device\n",
    ") { (motionSample: MotionSample) -> LangMotionBatch in    \n",
    "    let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let (motionPart, target) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength)\n",
    "    let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
    "    let singleBatch = LangMotionBatch(data: source,label: target)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func randomNumber(probabilities: [Double]) -> Int {\n",
    "    // https://stackoverflow.com/questions/30309556/generate-random-numbers-with-a-given-distribution\n",
    "    // Sum of all probabilities (so that we don't have to require that the sum is 1.0):\n",
    "    let sum = probabilities.reduce(0, +)\n",
    "    // Random number in the range 0.0 <= rnd < sum :\n",
    "    let rnd = Double.random(in: 0.0 ..< sum)\n",
    "    // Find the first interval of accumulated probabilities into which `rnd` falls:\n",
    "    var accum = 0.0\n",
    "    for (i, p) in probabilities.enumerated() {\n",
    "        accum += p\n",
    "        if rnd < accum {\n",
    "            return i\n",
    "        }\n",
    "    }\n",
    "    // This point might be reached due to floating point inaccuracies:\n",
    "    return (probabilities.count - 1)\n",
    "}\n",
    "\n",
    "public func gaussian_pdf(sample: Tensor<Float>, means: Tensor<Float>, variances: Tensor<Float>) -> Tensor<Float> {\n",
    "    // one-dim tensors\n",
    "    assert(sample.shape.count == 1)\n",
    "    assert(sample.shape == means.shape)\n",
    "    assert(sample.shape == variances.shape)\n",
    "    let a1 = sqrt(Float(2.0) * Float(np.pi)! * variances)\n",
    "    let a2 = -(sample - means).squared()\n",
    "    return Float(1.0) / a1 * exp(a2 / (2.0 * variances))\n",
    "}\n",
    "\n",
    "public func bernoulli_pdf(sample: Int, p: Float) -> Float {\n",
    "    let fSample = Float(sample)\n",
    "    return fSample * p + Float(1.0 - fSample) * (1.0 - p)\n",
    "}\n",
    "\n",
    "public class MotionDecoder2 {\n",
    "    public static func performNormalMixtureSampling(preds: MixtureModelPreds, nb_joints: Int, nb_mixtures: Int, maxMotionLength: Int) -> (motion: Tensor<Float>, log_probs: [Float], done: Tensor<Int32>) {\n",
    "        let TINY: Float = 1e-8\n",
    "        let motionLength = preds.mixtureMeans.shape[1]\n",
    "\n",
    "        var motion: Tensor<Float> = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        var log_probs: [Float] = [Float](repeating:0.0, count: motionLength)\n",
    "        var done: [Int32] = [Int32](repeating: 0, count: motionLength)\n",
    "\n",
    "        let all_means = preds.mixtureMeans.squeezingShape(at: 0)\n",
    "        let all_variances = preds.mixtureVars.squeezingShape(at: 0) + TINY\n",
    "        let weights = preds.mixtureWeights.squeezingShape(at: 0)\n",
    "        let stops = preds.stops[0, 0..., 0]\n",
    "\n",
    "        /// Sample joint values.\n",
    "        var samples = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        var means = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        var variances = Tensor<Float>(zeros: [motionLength, nb_joints])\n",
    "        for width_idx in 0..<motionLength {\n",
    "            // Decide which mixture to sample from\n",
    "            let p = weights[width_idx].scalars.map { Double($0)}\n",
    "            assert(p.count == nb_mixtures)\n",
    "            let mixture_idx = randomNumber(probabilities: p) //np.random.choice(range(nb_mixtures), p=p)\n",
    "\n",
    "            /// Sample from it.\n",
    "            let start_idx = mixture_idx * nb_joints\n",
    "            let m = all_means[width_idx, start_idx..<start_idx + nb_joints]\n",
    "            let v = all_variances[width_idx, start_idx..<start_idx + nb_joints]\n",
    "            assert(m.shape == [nb_joints])\n",
    "            assert(m.shape == v.shape)\n",
    "            // https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
    "            let s = np.random.normal(m.scalars, v.scalars)\n",
    "            samples[width_idx, 0...] = Tensor<Float>(Array(s)!)\n",
    "            means[width_idx, 0...] = m\n",
    "            variances[width_idx, 0...] = v\n",
    "        }\n",
    "\n",
    "        for idx in 0..<motionLength {\n",
    "            let sample = samples[idx]\n",
    "            let stop: Float = stops[idx].scalar!\n",
    "            // if done[idx] != 0 {\n",
    "            //     continue\n",
    "            // }\n",
    "            motion[idx] = sample\n",
    "            // https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.binomial.html\n",
    "            let sampled_stop: Int = Int(np.random.binomial(n: 1, p: stop))!\n",
    "            log_probs[idx] += log(gaussian_pdf(sample: sample, means: means[idx], variances: variances[idx])).sum().scalar!\n",
    "            log_probs[idx] += log(bernoulli_pdf(sample: sampled_stop, p: stop))\n",
    "            done[idx] = (sampled_stop == 0) ? 1 : 0\n",
    "        }\n",
    "        return (motion: motion, log_probs: log_probs, done: Tensor(done))\n",
    "    }\n",
    "    \n",
    "    public static func greedyDecodeMotion(\n",
    "        sentence: LangMotionBatch.Sentence, \n",
    "        startMotion: Tensor<Float>?,\n",
    "        transformer: LangMotionTransformer, \n",
    "        nbJoints: Int, \n",
    "        nbMixtures: Int, \n",
    "        maxMotionLength: Int,\n",
    "        memoryMultiplier: Float = 1.0\n",
    "    ) -> Tensor<Float> {\n",
    "        print(\"\\nEncode:\")\n",
    "        print(\"======\")\n",
    "        let memory = transformer.encode(input: sentence) //* memoryMultiplier\n",
    "        print(\"  memory.count: \\(memory.shape)\")     \n",
    "\n",
    "        print(\"\\nGenerate:\")\n",
    "        print(\"=========\")\n",
    "\n",
    "        // start with tensor for neutral motion frame        \n",
    "        var ys: Tensor<Float> = LangMotionBatch.startMotionToken(nbJoints: nbJoints).expandingShape(at: 0)\n",
    "        // or with supplied motion\n",
    "//         if startMotion != nil {\n",
    "//             ys = startMotion!.expandingShape(at:0)            \n",
    "//         }\n",
    "\n",
    "        print(\"ys.shape: \\(ys.shape)\")\n",
    "        \n",
    "        let maxMotionLength2 = maxMotionLength-ys.shape[1]+1\n",
    "//         print(\"maxMotionLength2: \\(maxMotionLength2)\")\n",
    "        \n",
    "        for step in 0..<maxMotionLength2 {\n",
    "//             print(\"step: \\(step)\")\n",
    "            // prepare input\n",
    "            // let motionPartMask = Tensor<Float>(LangMotionBatch.subsequentMask(size: ys.shape[1]))\n",
    "            let motionPartFlag = Tensor<Int32>(repeating: 1, shape: [1, ys.shape[1]])\n",
    "            let motionPartMask = LangMotionBatch.makeStandardMask(target: motionPartFlag, pad: 0)\n",
    "            let motionPart = LangMotionBatch.MotionPart(motion: ys, mask: motionPartMask)\n",
    "\n",
    "            // decode motion\n",
    "            let dedoderOutput = transformer.decode(sourceMask: sentence.mask, motionPart: motionPart, memory: memory)\n",
    "            \n",
    "//             print(\"dedoderOutput\")\n",
    "            \n",
    "            let mixtureModelInput = Tensor<Float>(concatenating: dedoderOutput.allOutputs, alongAxis: 2)\n",
    "//             print(\"mixtureModelInput.shape: \\(mixtureModelInput.shape)\")\n",
    "            let singlePreds = transformer.mixtureModel(mixtureModelInput[0...,-1].expandingShape(at: 0))\n",
    "\n",
    "            \n",
    "            // perform sampling\n",
    "            let (sampledMotion, _, _) = MotionDecoder.performNormalMixtureSampling(\n",
    "                preds: singlePreds, nb_joints: nbJoints, nb_mixtures: nbMixtures, maxMotionLength: maxMotionLength)\n",
    "            \n",
    "            // concatenate motion\n",
    "            ys = Tensor(concatenating: [ys, sampledMotion.expandingShape(at: 0)], alongAxis: 1)        \n",
    "        }\n",
    "        return ys.squeezingShape(at:0)[1...]\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct SampleMotionClip {\n",
    "    var sampleID: Int\n",
    "    var start: Int = 0\n",
    "    var length: Int = 1\n",
    "}\n",
    "\n",
    "public func getClippedMotionFrames(dataset: Lang2Motion, clipInfo: SampleMotionClip?) -> Tensor<Float>? {\n",
    "    if clipInfo != nil {\n",
    "    \n",
    "    let ms: MotionSample = dataset.motionSamples.filter { $0.sampleID == clipInfo!.sampleID } [0]\n",
    "    let clippedMotionFrames = ms.motion[clipInfo!.start..<clipInfo!.start+clipInfo!.length]\n",
    "    return clippedMotionFrames\n",
    "    } else {\n",
    "        return nil\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func greedyDecodeMotion(dataset: Lang2Motion, model: LangMotionTransformer, sentence: String, leadingFrames: SampleMotionClip?, prefix: String = \"prefix\", saveMotion: Bool = true, memoryMultiplier: Float = 0.0, motionsURL: URL?) {\n",
    "    let startMotion: Tensor<Float>? = getClippedMotionFrames(dataset: dataset, clipInfo: leadingFrames)\n",
    "    var leadingFramesStr = \"0\"\n",
    "    if startMotion != nil {\n",
    "        leadingFramesStr = \"\\(startMotion!.shape[0])\"\n",
    "    }\n",
    "    // TODO: incorporate done/stop signal\n",
    "    Context.local.learningPhase = .inference\n",
    "    print(\"\\ngreedyDecodeMotion(sentence: \\\"\\(sentence)\\\")\")\n",
    "\n",
    "    let processedSentence = textProcessor.preprocess(sentence: sentence, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    processedSentence.printSentence()\n",
    "\n",
    "    let decodedMotion = MotionDecoder2.greedyDecodeMotion(\n",
    "        sentence: processedSentence, \n",
    "        startMotion: startMotion,\n",
    "        transformer: model, \n",
    "        nbJoints: config.nbJoints, \n",
    "        nbMixtures: config.nbMixtures, \n",
    "        maxMotionLength: maxMotionLength,\n",
    "        memoryMultiplier: memoryMultiplier\n",
    "    )\n",
    "    print(\"  decodedMotion: min: \\(decodedMotion.min()), max: \\(decodedMotion.max())\")\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(decodedMotion)\n",
    "    print(\"  descaledMotion.shape: \\(descaledMotion.shape)\")\n",
    "    print(\"  descaledMotion: min: \\(descaledMotion.min()), max: \\(descaledMotion.max())\")\n",
    "    var imageURL: URL? = nil\n",
    "    \n",
    "    if !saveMotion { imageURL = nil } else {\n",
    "        imageURL = motionsURL!.appendingPathComponent(\"\\(prefix).png\")\n",
    "    }\n",
    "    // use joint groupping\n",
    "    let grouppedJointsMotion = MotionSample.grouppedJoints(motion: descaledMotion, jointNames: dataset.motionSamples[0].jointNames)\n",
    "    motionToImg(url: imageURL, motion: grouppedJointsMotion, motionFlag: nil, padTo: maxMotionLength, descr: \"\\(sentence), LF: \\(leadingFramesStr)\", cmapRange: 1.0)\n",
    "\n",
    "    if saveMotion {\n",
    "        print(\"Saved image: \\(imageURL!.path)\")\n",
    "        let jointNames = dataset.motionSamples[0].jointNames\n",
    "        let mmmXMLDoc = MMMWriter.getMMMXMLDoc(jointNames: jointNames, motion: descaledMotion)\n",
    "        let mmmURL = motionsURL!.appendingPathComponent(\"\\(prefix).mmm.xml\")\n",
    "        try! mmmXMLDoc.xmlData(options: XMLNode.Options.nodePrettyPrint).write(to: mmmURL)\n",
    "        print(\"Saved motion: \\(mmmURL.path)\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func showMotionSample(_ motionSample: MotionSample) {\n",
    "    let motion = motionSample.motion\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(motion)\n",
    "    let sentence = \"sample_id=\\(motionSample.sampleID), ann=\\(motionSample.annotations[0])\"\n",
    "\n",
    "    print(\"motion: min: \\(motion.min()), max: \\(motion.max())\")\n",
    "    print(\"descaledMotion.shape: \\(descaledMotion.shape)\")\n",
    "    print(\"descaledMotion: min: \\(descaledMotion.min()), max: \\(descaledMotion.max())\")\n",
    "\n",
    "    // use joint groupping\n",
    "    let jointNames = dataset.motionSamples[0].jointNames\n",
    "    let grouppedJointsMotion = MotionSample.grouppedJoints(motion: descaledMotion, jointNames: dataset.motionSamples[0].jointNames)\n",
    "    motionToImg(url: nil, motion: grouppedJointsMotion, motionFlag: nil, padTo: maxMotionLength, descr: sentence, cmapRange: 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func showMotion(motion: Tensor<Float>) {\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(motion)\n",
    "    let grouppedJointsMotion = MotionSample.grouppedJoints(motion: descaledMotion, jointNames: dataset.motionSamples[0].jointNames)\n",
    "    motionToImg(url: nil, motion: grouppedJointsMotion, motionFlag: nil, padTo: maxMotionLength, descr: \"\", cmapRange: 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func saveMotionToMMM(motion: Tensor<Float>, mmmURL: URL) {\n",
    "    let descaledMotion = dataset.scaler.inverse_transform(motion)\n",
    "    let jointNames = dataset.motionSamples[0].jointNames\n",
    "    let mmmXMLDoc = MMMWriter.getMMMXMLDoc(jointNames: jointNames, motion: descaledMotion)\n",
    "    try! mmmXMLDoc.xmlData(options: XMLNode.Options.nodePrettyPrint).write(to: mmmURL)\n",
    "    print(\"Saved motion: \\(mmmURL.path)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let runName = \"run_34\"\n",
    "let epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let runURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let checkpointURL = runURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
    "let motionsURL = runURL.appendingPathComponent(\"generated_motions\", isDirectory: true)\n",
    "try! FileManager().createDirectory(at: motionsURL, withIntermediateDirectories: true)\n",
    "\n",
    "let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(epoch)\")\n",
    "// let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode using leading motion frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find suitable motion sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let annotations = dataset.langRecs\n",
    "annotations.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let search = \"guitar\"\n",
    "let filteredAnns = annotations.filter { $0.text.contains(search) }\n",
    "print(filteredAnns.count)\n",
    "let startIdx = 0\n",
    "filteredAnns[startIdx..<startIdx+10].map { (sampleID: $0.sampleID, ann: $0.text) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select motion sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let selAnn = filteredAnns[3]\n",
    "let selSampleInfo = (sampleID: selAnn.sampleID, text: selAnn.text, length: selAnn.motionSample.motion.shape[0])\n",
    "\n",
    "print(\"Selected motion sample\")\n",
    "print(selSampleInfo)\n",
    "showMotionSample(selAnn.motionSample)\n",
    "saveMotionToMMM(motion: selAnn.motionSample.motion, mmmURL: motionsURL.appendingPathComponent(\"sample.mmm.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let clipInfo = SampleMotionClip(sampleID: selSampleInfo.sampleID, start: 14, length: 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let clippedMotionFrames: Tensor<Float>? = getClippedMotionFrames(dataset: dataset, clipInfo: clipInfo)\n",
    "print(\"\\n**** \\(clipInfo) ****\\n\")\n",
    "print(\"Actual length: \\(clippedMotionFrames!.shape[0])\")\n",
    "print(\"clippedMotionFrames: min: \\(clippedMotionFrames!.min()), max: \\(clippedMotionFrames!.max())\")\n",
    "showMotion(motion: clippedMotionFrames!)\n",
    "saveMotionToMMM(motion: clippedMotionFrames!, mmmURL: motionsURL.appendingPathComponent(\"clip.mmm.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let runName = \"run_34\"\n",
    "let epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "let runURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let checkpointURL = runURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
    "let motionsURL = runURL.appendingPathComponent(\"generated_motions\", isDirectory: true)\n",
    "try! FileManager().createDirectory(at: motionsURL, withIntermediateDirectories: true)\n",
    "\n",
    "let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(epoch)\")\n",
    "// let model = LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var genNum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var s: String = \"\"\n",
    "var lf: SampleMotionClip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"A person is walking forwards five steps.\"\n",
    "// s = \"A person is walking forwards.\"\n",
    "// lf = SampleMotionClip(sampleID: 1, start: 26, length: 2)\n",
    "lf = nil\n",
    "\n",
    "// s = \"A person plays the guitar.\"\n",
    "// lf = SampleMotionClip(sampleID: 1417, start: 14, length: 10)\n",
    "\n",
    "// s = \"The human plays air guitar and sways ans stands still.\"\n",
    "// s = \"The human walks in the straight line.\"\n",
    "// s = \"Someone is jogging.\"\n",
    "\n",
    "// s = \"a person waves with his both arms\"\n",
    "// s = \"a person is waving his hand.\"\n",
    "// s = \"A person runs.\"\n",
    "// s = \"A person kneels down.\"\n",
    "// s = \"A human walking backwards\"\n",
    "// s = \"A person walks 4 steps forward.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greedyDecodeMotion(dataset: dataset, model: model, sentence: s, leadingFrames: lf, \n",
    "    prefix: \"epoch_\\(epoch)_motion_\\(genNum)\", \n",
    "    saveMotion: true,  memoryMultiplier: 1.0, motionsURL: motionsURL\n",
    ")\n",
    "genNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
