{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionLangModels TrainingLoop Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import MotionLangModels\n",
    "import TrainingLoop\n",
    "import x10_optimizers_optimizer\n",
    "import Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PythonKit\n",
    "\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let runName = \"run_11\"\n",
    "let batchSize = 100\n",
    "let maxMotionLength = 50\n",
    "let maxTextSequenceLength = 40\n",
    "let nEpochs = 10\n",
    "\n",
    "var optimizerOpts = OptimizerOpts(\n",
    "    peakLearningRate: 5e-4,\n",
    "    beta1: 0.9,\n",
    "    beta2: 0.999,\n",
    "    useBiasCorrection: false,\n",
    "    lrSlopeMultiplier: 2,\n",
    "    nEpochs: nEpochs\n",
    ")\n",
    "\n",
    "// let datasetSize: DatasetSize = .multi_full\n",
    "let datasetSize: DatasetSize = .multi_mini\n",
    "\n",
    "print(\"runName: \\(runName)\")\n",
    "print(\"batchSize: \\(batchSize)\")\n",
    "print(\"maxMotionLength: \\(maxMotionLength)\")\n",
    "print(\"maxTextSequenceLength: \\(maxTextSequenceLength)\")\n",
    "print(\"nEpochs: \\(nEpochs)\")\n",
    "print(\"peakLearningRate: \\(optimizerOpts.peakLearningRate)\")\n",
    "print(\"datasetSize: \\(datasetSize)\")\n",
    "print(\"stepsPerEpoch: \\(optimizerOpts.stepsPerEpoch)\")\n",
    "\n",
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")\n",
    "\n",
    "let logdirURL = dataURL.appendingPathComponent(\"runs/Motion2lang/\", isDirectory: true)\n",
    "let rundirURL = logdirURL.appendingPathComponent(runName, isDirectory: true)\n",
    "let checkpointURL = rundirURL.appendingPathComponent(\"checkpoints\", isDirectory: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let device = Device.defaultXLA\n",
    "let device = Device.defaultTFEager\n",
    "print(\"backend: \\(device)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = LegacyTextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Motion2Lang(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    batchSize: batchSize,\n",
    "    minMotionLength: 20,\n",
    "    maxMotionLength: 100,\n",
    "    trainTestSplit: 0.9,\n",
    "    device: device\n",
    ") { (motionSample: MotionSample) -> MotionLangBatch in    \n",
    "    let singleBatch = textProcessor.preprocess(motionSample: motionSample, maxMotionLength: maxMotionLength, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate model\n",
    "let modelSize = 128\n",
    "let config = MotionLangTransformerConfig(\n",
    "    vocabSize: vocabulary.count,\n",
    "    nbJoints: 47,\n",
    "    layerCount: 6,\n",
    "    modelSize: modelSize,\n",
    "    feedForwardSize: 512,\n",
    "    headCount: 4,\n",
    "    dropoutProbability: 0.1,\n",
    "    sentenceMaxPositionalLength: 100,\n",
    "    motionMaxPositionalLength: 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func getModelStats(model: Any) -> (tensors: [String: Tensor<Float>], tt_sum: Double, tt_shape_sum: Int) {\n",
    "    var tensors = [String: Tensor<Float>]()\n",
    "    recursivelyObtainTensors(model, scope: \"model\", tensors: &tensors, separator: \"/\")\n",
    "    \n",
    "    var tt_sum = 0.0\n",
    "    var tt_shape_sum = 0\n",
    "    for (k, t) in tensors {\n",
    "        let t_sum = Double(t.sum().scalar!)\n",
    "        let t_shape_sum = t.shape.reduce(0, { x, y in x + y })\n",
    "        tt_sum += t_sum\n",
    "        tt_shape_sum += t_shape_sum\n",
    "    }\n",
    "    \n",
    "    return (tensors: tensors, tt_sum: tt_sum, tt_shape_sum: tt_shape_sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func encoderForwardPass(_ sample_id: Int, model: MotionLangTransformer) -> Tensor<Float> {\n",
    "    let motionSample = dataset.motionSampleDict[sample_id]!\n",
    "    print(\"\\nsample: \\(motionSample.sampleID), \\\"\\(motionSample.annotations[0])\\\", motion: \\(motionSample.timesteps[-1]) sec (\\(motionSample.motion.shape[0]) frames)\")\n",
    "\n",
    "    let singleBatch = textProcessor.preprocess(motionSample: motionSample, maxMotionLength: maxMotionLength, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let encoded = model.encode(input: singleBatch.source)\n",
    "    return encoded.lastLayerOutput\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func decoderForwardPass(_ sample_id: Int, model: MotionLangTransformer) -> Tensor<Float> {\n",
    "    let motionSample = dataset.motionSampleDict[sample_id]!\n",
    "    print(\"\\nsample: \\(motionSample.sampleID), \\\"\\(motionSample.annotations[0])\\\", motion: \\(motionSample.timesteps[-1]) sec (\\(motionSample.motion.shape[0]) frames)\")\n",
    "\n",
    "    let singleBatch = textProcessor.preprocess(motionSample: motionSample, maxMotionLength: maxMotionLength, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let encoded = model.encode(input: singleBatch.source)\n",
    "    let decoded = model.decode(input: singleBatch.source, memory: encoded.lastLayerOutput).lastLayerOutput\n",
    "    return decoded\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test new model against saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// create new model\n",
    "var newModel = MotionLangTransformer(config: config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let newModelStats = getModelStats(model: newModel)\n",
    "print(\"tensor sum \\(newModelStats.tt_sum)\")\n",
    "print(\"shape sum \\(newModelStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: newModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: newModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try! newModel.writeCheckpoint(to: checkpointURL, name: \"newModel.saved\")\n",
    "\n",
    "var loadedModel = try! MotionLangTransformer(checkpoint: logdirURL.appendingPathComponent(\"run_11/checkpoints\"), config: config, name: \"newModel.saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let loadedModelStats = getModelStats(model: loadedModel)\n",
    "print(\"tensor sum \\(loadedModelStats.tt_sum)\")\n",
    "print(\"shape sum \\(loadedModelStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: loadedModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: loadedModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try! loadedModel.writeCheckpoint(to: checkpointURL, name: \"loadedModel.saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test trained model against resaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model50 = try! MotionLangTransformer(checkpoint: logdirURL.appendingPathComponent(\"run_11/checkpoints\"), config: config, name: \"model.e50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let model50Stats = getModelStats(model: model50)\n",
    "print(\"tensor sum \\(model50Stats.tt_sum)\")\n",
    "print(\"shape sum \\(model50Stats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: model50).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: model50).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try! model50.writeCheckpoint(to: checkpointURL, name: \"model.e50.re-saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var modelResaved = try! MotionLangTransformer(checkpoint: logdirURL.appendingPathComponent(\"run_11/checkpoints\"), config: config, name: \"model.e50.re-saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let modelResavedStats = getModelStats(model: modelResaved)\n",
    "print(\"tensor sum \\(modelResavedStats.tt_sum)\")\n",
    "print(\"shape sum \\(modelResavedStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: modelResaved).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: modelResaved).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
