{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionLangModels TrainingLoop Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import MotionLangModels\n",
    "import TrainingLoop\n",
    "import x10_optimizers_optimizer\n",
    "import Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PythonKit\n",
    "\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let runName = \"run_18\"\n",
    "let batchSize = 10\n",
    "let maxMotionLength = 100\n",
    "let maxTextSequenceLength = 40\n",
    "let nEpochs = 1\n",
    "\n",
    "var optimizerOpts = OptimizerOpts(\n",
    "    peakLearningRate: 1e-3,\n",
    "    beta1: 0.9,\n",
    "    beta2: 0.999,\n",
    "    useBiasCorrection: false,\n",
    "    lrSlopeMultiplier: 2,\n",
    "    nEpochs: nEpochs\n",
    ")\n",
    "\n",
    "// let datasetSize: DatasetSize = .multi_full\n",
    "let datasetSize: DatasetSize = .micro\n",
    "\n",
    "print(\"runName: \\(runName)\")\n",
    "print(\"batchSize: \\(batchSize)\")\n",
    "print(\"maxMotionLength: \\(maxMotionLength)\")\n",
    "print(\"maxTextSequenceLength: \\(maxTextSequenceLength)\")\n",
    "print(\"nEpochs: \\(nEpochs)\")\n",
    "print(\"peakLearningRate: \\(optimizerOpts.peakLearningRate)\")\n",
    "print(\"datasetSize: \\(datasetSize)\")\n",
    "print(\"stepsPerEpoch: \\(optimizerOpts.stepsPerEpoch)\")\n",
    "\n",
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")\n",
    "\n",
    "let logdirURL = dataURL.appendingPathComponent(\"runs/Motion2lang/\", isDirectory: true)\n",
    "let rundirURL = logdirURL.appendingPathComponent(runName, isDirectory: true)\n",
    "let checkpointURL = rundirURL.appendingPathComponent(\"checkpoints\", isDirectory: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let device = Device.defaultXLA\n",
    "let device = Device.defaultTFEager\n",
    "print(\"backend: \\(device)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = LegacyTextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Motion2Lang(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    batchSize: batchSize,\n",
    "    minMotionLength: 20,\n",
    "    maxMotionLength: 100,\n",
    "    trainTestSplit: 0.9,\n",
    "    device: device\n",
    ") { (motionSample: MotionSample) -> MotionLangBatch in    \n",
    "    let singleBatch = textProcessor.preprocess(motionSample: motionSample, maxMotionLength: maxMotionLength, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate model\n",
    "let modelSize = 64\n",
    "let config = MotionLangTransformerConfig(\n",
    "    vocabSize: vocabulary.count,\n",
    "    nbJoints: 47,\n",
    "    layerCount: 2,\n",
    "    modelSize: modelSize,\n",
    "    feedForwardSize: 128,\n",
    "    headCount: 2,\n",
    "    dropoutProbability: 0.1,\n",
    "    sentenceMaxPositionalLength: 100,\n",
    "    motionMaxPositionalLength: 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func getModelStats(model: Any) -> (tensors: [String: Tensor<Float>], tt_sum: Double, tt_shape_sum: Int) {\n",
    "    var tensors = [String: Tensor<Float>]()\n",
    "    recursivelyObtainTensors(model, scope: \"model\", tensors: &tensors, separator: \"/\")\n",
    "    \n",
    "    var tt_sum = 0.0\n",
    "    var tt_shape_sum = 0\n",
    "    for (k, t) in tensors {\n",
    "        let t_sum = Double(t.sum().scalar!)\n",
    "        let t_shape_sum = t.shape.reduce(0, { x, y in x + y })\n",
    "        tt_sum += t_sum\n",
    "        tt_shape_sum += t_shape_sum\n",
    "    }\n",
    "    \n",
    "    return (tensors: tensors, tt_sum: tt_sum, tt_shape_sum: tt_shape_sum)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func encoderForwardPass(_ sample_id: Int, model: MotionLangTransformer) -> Tensor<Float> {\n",
    "    let motionSample = dataset.motionSampleDict[sample_id]!\n",
    "    print(\"\\nsample: \\(motionSample.sampleID), \\\"\\(motionSample.annotations[0])\\\", motion: \\(motionSample.timesteps[-1]) sec (\\(motionSample.motion.shape[0]) frames)\")\n",
    "\n",
    "    let singleBatch = textProcessor.preprocess(motionSample: motionSample, maxMotionLength: maxMotionLength, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let encoded = model.encode(input: singleBatch.source)\n",
    "    return encoded.lastLayerOutput\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func decoderForwardPass(_ sample_id: Int, model: MotionLangTransformer) -> Tensor<Float> {\n",
    "    let motionSample = dataset.motionSampleDict[sample_id]!\n",
    "    print(\"\\nsample: \\(motionSample.sampleID), \\\"\\(motionSample.annotations[0])\\\", motion: \\(motionSample.timesteps[-1]) sec (\\(motionSample.motion.shape[0]) frames)\")\n",
    "\n",
    "    let singleBatch = textProcessor.preprocess(motionSample: motionSample, maxMotionLength: maxMotionLength, maxTextSequenceLength: maxTextSequenceLength)\n",
    "    let encoded = model.encode(input: singleBatch.source)\n",
    "    let decoded = model.decode(input: singleBatch.source, memory: encoded.lastLayerOutput).lastLayerOutput\n",
    "    return decoded\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// create new model\n",
    "var newModel = MotionLangTransformer(config: config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerOpts.stepsPerEpoch = dataset.motionSamples.count/batchSize // function of training set size and batching configuration\n",
    "let optimizerWrapper = OptimizerWrapper(opts: optimizerOpts, model: newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// stats recorder\n",
    "let statsRecorder = StatsRecorder(logdirURL: rundirURL)\n",
    "\n",
    "@differentiable(wrt: y_pred)\n",
    "func embeddedSoftmaxCrossEntropy(y_pred: Tensor<Float>, y_true: MotionLangBatch.MLTarget) -> Tensor<Float> {\n",
    "    let resultSize = y_true.targetTruth.shape.last! * y_true.targetTruth.shape.first!\n",
    "    let logits = y_pred.reshaped(to: [resultSize, -1])\n",
    "    let labels = y_true.targetTruth.reshaped(to: [-1])\n",
    "    // TODO: ignore padded entries\n",
    "    return softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: fix epoch numbering\n",
    "public func saveCheckpoint<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent, model: MotionLangTransformer) throws {\n",
    "    if event == .epochEnd {\n",
    "        guard let epochIndex = loop.epochIndex else {\n",
    "            return\n",
    "        }\n",
    "        try! model.writeCheckpoint(to: checkpointURL, name: \"model.e\\(epochIndex+1).in_fit.n\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Training loop\n",
    "print(\"\\nSetting up the training loop\")\n",
    "let trainingProgress = TrainingProgress(metrics: [.loss])\n",
    "var trainingLoop: TrainingLoop = TrainingLoop(\n",
    "    training: dataset.trainEpochs,\n",
    "    validation: dataset.testBatches,\n",
    "    optimizer: optimizerWrapper.optimizer,\n",
    "    lossFunction:  embeddedSoftmaxCrossEntropy,\n",
    "    callbacks: [trainingProgress.update, statsRecorder.writeStats, optimizerWrapper.learningRateUpdater, saveCheckpoint]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Transformer for the Motion2lang task!\")\n",
    "// FIXME: epoch loop workaround for checkpoint saving\n",
    "for epochIndex in start_epoch..<start_epoch+nEpochs {\n",
    "    print(\"epoch \\(epochIndex+1)/\\(start_epoch + nEpochs)\")\n",
    "    statsRecorder.epochIndex = epochIndex\n",
    "    try! trainingLoop.fit(&newModel, epochs: 1, on: device)\n",
    "    try! newModel.writeCheckpoint(to: checkpointURL, name: \"model.e\\(epochIndex+1).out_of_fit.n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let newModelStats = getModelStats(model: newModel)\n",
    "print(\"tensor sum \\(newModelStats.tt_sum)\")\n",
    "print(\"shape sum \\(newModelStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test in_fit saved model against out_of_fit saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var inModel = try! MotionLangTransformer(checkpoint: checkpointURL, config: config, name: \"model.e1.in_fit.n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let inModelStats = getModelStats(model: inModel)\n",
    "print(\"tensor sum \\(inModelStats.tt_sum)\")\n",
    "print(\"shape sum \\(inModelStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: inModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: inModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var outModel = try! MotionLangTransformer(checkpoint: checkpointURL, config: config, name: \"model.e1.out_of_fit.n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let outModelStats = getModelStats(model: outModel)\n",
    "print(\"tensor sum \\(outModelStats.tt_sum)\")\n",
    "print(\"shape sum \\(outModelStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: outModel).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: outModel).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare per tensor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (nk, nt) in inModelStats.tensors {\n",
    "    let lt = outModelStats.tensors[nk]\n",
    "    let nt_sum = Double(nt.sum().scalar!)\n",
    "    let lt_sum = Double(lt!.sum().scalar!)\n",
    "    if nt_sum != lt_sum {\n",
    "        print(nk)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (nk, nt) in inModelStats.tensors {\n",
    "    let lt = outModelStats.tensors[nk]\n",
    "    let nt_sum = Double(nt.sum().scalar!)\n",
    "    let lt_sum = Double(lt!.sum().scalar!)\n",
    "    if nt_sum != lt_sum {\n",
    "        print(nk)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array(newModelStats.tensors.keys).sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MotionLangTransformer: ExportableLayer {\n",
    "    public var nameMappings: [String: String] {\n",
    "        [\n",
    "            \"embedding\": \"embedding\",\n",
    "            \"motionNorm\": \"motionNorm\",\n",
    "            \"motionDense\": \"motionDense\",\n",
    "            \"generator\": \"generator\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func recursivelyObtainTensors2(\n",
    "    _ obj: Any, scope: String? = nil, tensors: inout [String: Tensor<Float>], separator: String\n",
    ") {\n",
    "    \n",
    "    let m = Mirror(reflecting: obj)\n",
    "    let nameMappings: [String: String]\n",
    "    if let exportableLayer = obj as? ExportableLayer {\n",
    "        if let model = obj as? MotionLangTransformer {\n",
    "            nameMappings = [\n",
    "                \"embedding\": \"embedding\",\n",
    "                \"motionNorm\": \"motionNorm\",\n",
    "                \"motionDense\": \"motionDense\",\n",
    "                \"generator\": \"generator\"\n",
    "            ]\n",
    "        }\n",
    "        else {\n",
    "            nameMappings = exportableLayer.nameMappings\n",
    "        }\n",
    "        print(type(of:exportableLayer), nameMappings)\n",
    "    } else {\n",
    "        if (obj is Int) || (obj is Bool) || (obj is Tensor<Float>) ||\n",
    "           (obj is Double) || (obj is Float) || (obj is Dropout<Float>) ||\n",
    "           (obj is Parameter<Float>) || (obj is Sequential<Embedding<Float>, PositionalEncoding>)\n",
    "        {}\n",
    "        else {\n",
    "            let s = \"\\(scope!) -> \\(type(of:obj))\"\n",
    "            if !s.contains(\"Tensor\") {\n",
    "                // print(s)\n",
    "            }\n",
    "        }\n",
    "        nameMappings = [:]\n",
    "    }\n",
    "\n",
    "    var repeatedLabels: [String: Int] = [:]\n",
    "    func suffix(for label: String) -> String {\n",
    "        if let currentSuffix = repeatedLabels[label] {\n",
    "            repeatedLabels[label] = currentSuffix + 1\n",
    "            return \"\\(currentSuffix + 1)\"\n",
    "        } else {\n",
    "            repeatedLabels[label] = 0\n",
    "            return \"0\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    let hasSuffix = (m.children.first?.label == nil)\n",
    "\n",
    "    var path = scope\n",
    "    for child in m.children {\n",
    "        let label = child.label ?? \"h\"\n",
    "\n",
    "        if let remappedLabel = nameMappings[label] {\n",
    "            let labelSuffix = hasSuffix ? suffix(for: remappedLabel) : \"\"\n",
    "            let conditionalSeparator = remappedLabel == \"\" ? \"\" : separator\n",
    "\n",
    "            path = (scope != nil ? scope! + conditionalSeparator : \"\") + remappedLabel + labelSuffix\n",
    "            if let tensor = child.value as? Tensor<Float> {\n",
    "                tensors[path!] = tensor\n",
    "            }\n",
    "        }\n",
    "        recursivelyObtainTensors2(child.value, scope: path, tensors: &tensors, separator: separator)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var tensors = [String: Tensor<Float>]()\n",
    "recursivelyObtainTensors2(newModel, scope: \"model\", tensors: &tensors, separator: \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array(tensors.keys).sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test trained model against resaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model50 = try! MotionLangTransformer(checkpoint: logdirURL.appendingPathComponent(\"run_11/checkpoints\"), config: config, name: \"model.e50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let model50Stats = getModelStats(model: model50)\n",
    "print(\"tensor sum \\(model50Stats.tt_sum)\")\n",
    "print(\"shape sum \\(model50Stats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: model50).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: model50).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try! model50.writeCheckpoint(to: checkpointURL, name: \"model.e50.re-saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var modelResaved = try! MotionLangTransformer(checkpoint: logdirURL.appendingPathComponent(\"run_11/checkpoints\"), config: config, name: \"model.e50.re-saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let modelResavedStats = getModelStats(model: modelResaved)\n",
    "print(\"tensor sum \\(modelResavedStats.tt_sum)\")\n",
    "print(\"shape sum \\(modelResavedStats.tt_shape_sum)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderForwardPass(dataset.motionSamples[0].sampleID, model: modelResaved).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoderForwardPass(dataset.motionSamples[0].sampleID, model: modelResaved).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
